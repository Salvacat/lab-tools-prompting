{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f66dbe-192b-471c-9cb8-e9b365e61bbb",
   "metadata": {},
   "source": [
    "# Lab | Tools prompting\n",
    "\n",
    "**Replace the existing two tools decorators, by creating 3 new ones and adjust the prompts accordingly**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b94240",
   "metadata": {},
   "source": [
    "### How to add ad-hoc tool calling capability to LLMs and Chat Models\n",
    "\n",
    ":::{.callout-caution}\n",
    "\n",
    "Some models have been fine-tuned for tool calling and provide a dedicated API for tool calling. Generally, such models are better at tool calling than non-fine-tuned models, and are recommended for use cases that require tool calling. Please see the [how to use a chat model to call tools](/docs/how_to/tool_calling) guide for more information.\n",
    "\n",
    "In this guide, we'll see how to add **ad-hoc** tool calling support to a chat model. This is an alternative method to invoke tools if you're using a model that does not natively support tool calling.\n",
    "\n",
    "We'll do this by simply writing a prompt that will get the model to invoke the appropriate tools. Here's a diagram of the logic:\n",
    "\n",
    "<br>\n",
    "\n",
    "![chain](https://education-team-2020.s3.eu-west-1.amazonaws.com/ai-eng/tool_chain.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a22cb8-19e7-450a-9d1b-6848d2c81cd1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll need to install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c556c5e-b785-428b-8e7d-efd34a2a1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897bc01e-cc2b-4400-8a64-db4aa56085d3",
   "metadata": {},
   "source": [
    "If you'd like to use LangSmith, uncomment the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efb4170-b95b-4d29-8f57-09509f3ba6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec6409b-21e5-4d0a-8a46-c4ef0b055dd3",
   "metadata": {},
   "source": [
    "You can select any of the given models for this how-to guide. Keep in mind that most of these models already [support native tool calling](/docs/integrations/chat/), so using the prompting strategy shown here doesn't make sense for these models, and instead you should follow the [how to use a chat model to call tools](/docs/how_to/tool_calling) guide.\n",
    "\n",
    "```{=mdx}\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs openaiParams={`model=\"gpt-4\"`} />\n",
    "```\n",
    "\n",
    "To illustrate the idea, we'll use `phi3` via Ollama, which does **NOT** have native support for tool calling. If you'd like to use `Ollama` as well follow [these instructions](/docs/integrations/chat/ollama/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f779ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "model_2 = ChatOpenAI(model= \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "424be968-2806-4d1a-a6aa-5499ae20fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_community.llms import Ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"phi3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68946881",
   "metadata": {},
   "source": [
    "## Create a tool\n",
    "\n",
    "First, let's create an `add` and `multiply` tools. For more information on creating custom tools, please see [this guide](/docs/how_to/custom_tools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337baf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Salva\\Anaconda3\\envs\\rag_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "# Load the model and processor \n",
    "hf_model = \"Salesforce/blip-image-captioning-large\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "processor = BlipProcessor.from_pretrained(hf_model)\n",
    "model = BlipForConditionalGeneration.from_pretrained(hf_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d84faeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d3a6e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "image_caption\n",
      "Given the URL of an image, download it and return a caption describing the image.\n",
      "{'url': {'title': 'Url', 'type': 'string'}}\n",
      "--\n",
      "search_image\n",
      "Search for an image on the web based on a query and return a URL.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n",
      "--\n",
      "seo_analysis\n",
      "Analyze the SEO of a given URL and return basic SEO metrics.\n",
      "{'url': {'title': 'Url', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "# Image Captioning Tool\n",
    "@tool\n",
    "def image_caption(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Given the URL of an image, download it and return a caption describing the image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "\n",
    "        # Download the image from the URL\n",
    "        img = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
    "\n",
    "        # Preprocess the image and generate caption\n",
    "        inputs = processor(img, return_tensors=\"pt\").to(device)\n",
    "        out = model.generate(**inputs, max_new_tokens=20)\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "        return caption\n",
    "    except Exception as e:\n",
    "        return f\"Error generating caption: {str(e)}\"\n",
    "\n",
    "\n",
    "# Image Search Tool\n",
    "@tool\n",
    "def search_image(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for an image on the web based on a query and return a URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        search_url = f\"https://google.com/image-search?q={query}\"\n",
    "        response = requests.get(search_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get(\"image_url\", \"No results found.\")\n",
    "        else:\n",
    "            return \"Failed to search for image.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error during image search: {str(e)}\"\n",
    "\n",
    "\n",
    "# SEO Analysis Tool\n",
    "@tool\n",
    "def seo_analysis(url: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze the SEO of a given URL and return basic SEO metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Basic SEO Analysis - Example\n",
    "            html_content = response.text\n",
    "            seo_metrics = {\n",
    "                \"title\": html_content.split('<title>')[1].split('</title>')[0] if \"<title>\" in html_content else \"No title tag found\",\n",
    "                \"meta_description\": html_content.split('name=\"description\" content=\"')[1].split('\"')[0] if 'name=\"description\" content=\"' in html_content else \"No meta description found\",\n",
    "                \"h1_tags\": html_content.count('<h1>'),\n",
    "                \"number_of_links\": html_content.count('<a href=')\n",
    "            }\n",
    "            return seo_metrics\n",
    "        else:\n",
    "            return {\"error\": \"Failed to retrieve the webpage.\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "# Register the tools for the agent to use\n",
    "tools = [image_caption, search_image, seo_analysis]\n",
    "\n",
    "# Inspect the tools for debugging\n",
    "for t in tools:\n",
    "    print(\"--\")\n",
    "    print(t.name)\n",
    "    print(t.description)\n",
    "    print(t.args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd690e-e54d-4209-91a4-181f69a452ac",
   "metadata": {},
   "source": [
    "## Creating our prompt\n",
    "\n",
    "We'll want to write a prompt that specifies the tools the model has access to, the arguments to those tools, and the desired output format of the model. In this case we'll instruct it to output a JSON blob of the form `{\"name\": \"...\", \"arguments\": {...}}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2063b564-25ca-4729-a45f-ba4633175b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_caption(url: str) -> str - Given the URL of an image, download it and return a caption describing the image.\n",
      "search_image(query: str) -> str - Search for an image on the web based on a query and return a URL.\n",
      "seo_analysis(url: str) -> dict - Analyze the SEO of a given URL and return basic SEO metrics.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import render_text_description\n",
    "\n",
    "rendered_tools = render_text_description(tools)\n",
    "print(rendered_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f02f1dce-76e7-4ca9-9bac-5af496131fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\\\n",
    "You are an assistant that has access to the following set of tools. \n",
    "Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. \n",
    "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "\n",
    "The `arguments` should be a dictionary, with keys corresponding \n",
    "to the argument names and the values corresponding to the requested values.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8623e03-60eb-4439-b57b-ecbcebc61b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"search_image\",\n",
      "  \"arguments\": {\n",
      "    \"query\": \"dog\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | model_2\n",
    "message = chain.invoke({\"input\": \"search image of a dog\"})\n",
    "\n",
    "# Let's take a look at the output from the model\n",
    "# if the model is an LLM (not a chat model), the output will be a string.\n",
    "if isinstance(message, str):\n",
    "    print(message)\n",
    "else:  # Otherwise it's a chat model\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df2cd5-b6fa-4b10-892d-e8692c7931e5",
   "metadata": {},
   "source": [
    "## Adding an output parser\n",
    "\n",
    "We'll use the `JsonOutputParser` for parsing our models output to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f129f5bd-127c-4c95-8f34-8f437da7ca8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_image', 'arguments': {'query': 'dog'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | model_2 | JsonOutputParser()\n",
    "chain.invoke({\"input\": \"image of a dog\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f08255-f146-4f4a-be43-5c21c1d3ae83",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "\n",
    "🎉 Amazing! 🎉 We now instructed our model on how to **request** that a tool be invoked.\n",
    "\n",
    "Now, let's create some logic to actually run the tool!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29dd4c-8eb5-457f-92d1-8add076404dc",
   "metadata": {},
   "source": [
    "## Invoking the tool 🏃\n",
    "\n",
    "Now that the model can request that a tool be invoked, we need to write a function that can actually invoke \n",
    "the tool.\n",
    "\n",
    "The function will select the appropriate tool by name, and pass to it the arguments chosen by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faee95e0-4095-4310-991f-9e9465c6738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, TypedDict\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "class ToolCallRequest(TypedDict):\n",
    "    \"\"\"A typed dict that shows the inputs into the invoke_tool function.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "\n",
    "def invoke_tool(\n",
    "    tool_call_request: ToolCallRequest, config: Optional[RunnableConfig] = None\n",
    "):\n",
    "    \"\"\"A function that we can use the perform a tool invocation.\n",
    "\n",
    "    Args:\n",
    "        tool_call_request: a dict that contains the keys name and arguments.\n",
    "            The name must match the name of a tool that exists.\n",
    "            The arguments are the arguments to that tool.\n",
    "        config: This is configuration information that LangChain uses that contains\n",
    "            things like callbacks, metadata, etc.See LCEL documentation about RunnableConfig.\n",
    "\n",
    "    Returns:\n",
    "        output from the requested tool\n",
    "    \"\"\"\n",
    "    tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "    name = tool_call_request[\"name\"]\n",
    "    requested_tool = tool_name_to_tool[name]\n",
    "    return requested_tool.invoke(tool_call_request[\"arguments\"], config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4957532-9e0c-47f6-bb62-0fd789ac1d3e",
   "metadata": {},
   "source": [
    "Let's test this out 🧪!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715af6e1-935d-4bc0-a3d2-646ecf8a329b",
   "metadata": {},
   "source": [
    "## Let's put it together\n",
    "\n",
    "Let's put it together into a chain that creates a calculator with add and multiplication capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0555b384-fde6-4404-86e0-7ea199003d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there is a dog that is standing on a rock near a tree'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model_2 | JsonOutputParser() | invoke_tool\n",
    "chain.invoke({\"input\": \"https://i.natgeofe.com/n/5d00b0cc-ab95-4522-ad13-7c65b7589e6b/NationalGeographic_748483.jpg?w=718&h=479\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbbece9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'FAQ | thebarefooter',\n",
       " 'meta_description': 'Why wear barefoot shoes? Are minimalist shoes good for me? Can barefoot shoes help with my bunions? All the barefoot and minimalist footwear burning questions are answered at The Barefooter FAQ. Come on in and ask any further questions.',\n",
       " 'h1_tags': 0,\n",
       " 'number_of_links': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model_2 | JsonOutputParser() | invoke_tool\n",
    "chain.invoke({\"input\": \"https://www.thebarefooter.com/faq\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9c5aa-f60a-4017-af6f-1ff6e04bfb61",
   "metadata": {},
   "source": [
    "## Returning tool inputs\n",
    "\n",
    "It can be helpful to return not only tool outputs but also tool inputs. We can easily do this with LCEL by `RunnablePassthrough.assign`-ing the tool output. This will take whatever the input is to the RunnablePassrthrough components (assumed to be a dictionary) and add a key to it while still passing through everything that's currently in the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45404406-859d-4caa-8b9d-5838162c80a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply',\n",
       " 'arguments': {'x': 13, 'y': 4.14137281},\n",
       " 'output': 53.83784653}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    prompt | model | JsonOutputParser() | RunnablePassthrough.assign(output=invoke_tool)\n",
    ")\n",
    "chain.invoke({\"input\": \"what's thirteen times 4.14137281\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797fe82-ea35-4cba-834a-1caf9740d184",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "This how-to guide shows the \"happy path\" when the model correctly outputs all the required tool information.\n",
    "\n",
    "In reality, if you're using more complex tools, you will start encountering errors from the model, especially for models that have not been fine tuned for tool calling and for less capable models.\n",
    "\n",
    "You will need to be prepared to add strategies to improve the output from the model; e.g.,\n",
    "\n",
    "1. Provide few shot examples.\n",
    "2. Add error handling (e.g., catch the exception and feed it back to the LLM to ask it to correct its previous output)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
